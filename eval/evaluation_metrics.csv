samples,accuracy,precision,recall,f1,model,scenario,reference,convert_no
1920,0.7958333333333333,0.5767475392829771,0.5485105896816038,0.5495589813950533,GPT-4o base,Human Answer,Human Answer,True
1920,0.8640625,0.6002233854542894,0.5966401385466025,0.5910173095859692,GPT-4o FT,Human Answer,Human Answer,True
1896,0.82542194092827,0.5857965638721881,0.5755632112972301,0.5705525828255793,GPT-4o AP,Human Answer,Human Answer,True
1919,0.805106826472121,0.805106826472121,0.805106826472121,0.805106826472121,gpt5-mini,Human Answer,Human Answer,True
1920,0.7192708333333333,0.5050282024387032,0.506405523508488,0.4951178193499467,Llama3.1-70B base,Human Answer,Human Answer,True
1920,0.8260416666666667,0.5457065162617109,0.5144225969868731,0.5178738489803678,Llama3.1-70B FT,Human Answer,Human Answer,True
1910,0.7041884816753927,0.5225300919494227,0.5393684761544308,0.5201174167145595,llama-3.1-70B AP,Human Answer,Human Answer,True
1906,0.742392444910808,0.5442599359629056,0.5837193253415509,0.5466374026189924,GPT-4o base,Updated Human Answer,Updated Human Answer,True
1906,0.7465897166841553,0.5478298952892179,0.65643756819608,0.576917204576965,GPT-4o FT,Updated Human Answer,Updated Human Answer,True
1893,0.7522451135763338,0.582297292235883,0.6799044711616167,0.6069691873856816,GPT-4o AP,Updated Human Answer,Updated Human Answer,True
1919,0.559666492965086,0.559666492965086,0.559666492965086,0.559666492965086,gpt5-mini,Updated Human Answer,Updated Human Answer,True
1906,0.6720881427072403,0.4973686768666443,0.5797736682332091,0.5160814410310353,Llama3.1-70B base,Updated Human Answer,Updated Human Answer,True
1906,0.7859391395592865,0.5745535910497643,0.6353132938578359,0.5844975395671024,Llama3.1-70B FT,Updated Human Answer,Updated Human Answer,True
1902,0.6077812828601472,0.5272671517556687,0.6206670020921233,0.5466964667799441,llama-3.1-70B AP,Updated Human Answer,Updated Human Answer,True
1893,0.5134706814580031,0.579669731058643,0.6769309242880249,0.6038145797360428,GPT-4o AP,Updated Human Answer – literal,Updated Human Answer,False
1902,0.4011566771819138,0.5187248057126819,0.6106094544351713,0.5376574171752758,llama-3.1-70B AP,Updated Human Answer – literal,Updated Human Answer,False
1919,0.559666492965086,0.559666492965086,0.559666492965086,0.559666492965086,gpt5-mini,Updated Human Answer – literal,Updated Human Answer,False
840,0.9071428571428571,0.8979348837209302,0.8704133445091751,0.882610939112487,GPT-4o base,Human Answer – Yes/No questions,Human Answer,True
840,0.9452380952380952,0.9359156308113927,0.931843528979835,0.9338604732080723,GPT-4o FT,Human Answer – Yes/No questions,Human Answer,True
840,0.9119047619047619,0.8880844645550527,0.9010314562999189,0.8941532258064515,GPT-4o AP,Human Answer – Yes/No questions,Human Answer,True
840,0.9095238095238095,0.9209023090586146,0.9080417570085689,0.913871371432778,gpt5-mini,Human Answer – Yes/No questions,Human Answer,True
840,0.8714285714285714,0.8505764429431635,0.830492037212782,0.8396129638930148,Llama3.1-70B base,Human Answer – Yes/No questions,Human Answer,True
840,0.9142857142857143,0.9233357308399265,0.8667419419641311,0.8894518978452896,Llama3.1-70B FT,Human Answer – Yes/No questions,Human Answer,True
840,0.8261904761904761,0.8016029743049242,0.8607707174474747,0.8107407407407408,llama-3.1-70B AP,Human Answer – Yes/No questions,Human Answer,True
840,0.8369047619047619,0.7164837209302325,0.827649125968643,0.7468538206199309,GPT-4o base,Updated Human Answer – Yes/No questions,Updated Human Answer,True
840,0.8321428571428572,0.7223779694906249,0.8581951703009552,0.7530990825457153,GPT-4o FT,Updated Human Answer – Yes/No questions,Updated Human Answer,True
840,0.8107142857142857,0.7037204625439919,0.8422914038565508,0.7291306261268478,GPT-4o AP,Updated Human Answer – Yes/No questions,Updated Human Answer,True
840,0.7952380952380952,0.7188952042628775,0.8432149936925573,0.7360717974018807,gpt5-mini,Updated Human Answer – Yes/No questions,Updated Human Answer,True
840,0.8083333333333333,0.6832427669261272,0.7808839430528023,0.7071422349969514,Llama3.1-70B base,Updated Human Answer – Yes/No questions,Updated Human Answer,True
840,0.8583333333333333,0.7391273076000959,0.8368850243287078,0.7707475542862952,Llama3.1-70B FT,Updated Human Answer – Yes/No questions,Updated Human Answer,True
840,0.7035714285714286,0.6556761389630471,0.8027797801405658,0.6382259997820638,llama-3.1-70B AP,Updated Human Answer – Yes/No questions,Updated Human Answer,True
