samples,accuracy,precision,recall,f1,tp,tn,fp,fn,model,scenario,reference,convert_no
1920,0.8989583333333333,0.8681177976952625,0.881664499349805,0.8748387096774195,678,1048,103,91,GPT-5 base,Human Answer,Human Answer,True
1920,0.8265625,0.8707482993197279,0.6657997399219766,0.7546057479734709,512,1075,76,257,GPT-4o base,Human Answer,Human Answer,True
1920,0.8979166666666667,0.920704845814978,0.8153446033810143,0.8648275862068966,627,1097,54,142,GPT-4o FT,Human Answer,Human Answer,True
1920,0.8135416666666667,0.7803547066848567,0.7438231469440832,0.7616511318242344,572,990,161,197,GPT-4o AP Before,Human Answer,Human Answer,True
1920,0.8270833333333333,0.8189781021897811,0.729518855656697,0.7716643741403025,561,1027,124,208,GPT-4o AP,Human Answer,Human Answer,True
1920,0.83125,0.8537360890302067,0.6983094928478544,0.7682403433476395,537,1059,92,232,GPT-4o AP After,Human Answer,Human Answer,True
1920,0.7734375,0.7392550143266475,0.6710013003901171,0.7034764826175869,516,969,182,253,Llama3.1-70B base,Human Answer,Human Answer,True
1920,0.8510416666666667,0.948051948051948,0.6644993498049415,0.7813455657492355,511,1123,28,258,Llama3.1-70B FT,Human Answer,Human Answer,True
1920,0.8052083333333333,0.7496839443742098,0.7711313394018205,0.7602564102564101,593,953,198,176,Llama3.1-70B AP Before,Human Answer,Human Answer,True
1920,0.7390625,0.6456521739130435,0.7724317295188556,0.7033747779751331,594,825,326,175,Llama3.1-70B AP,Human Answer,Human Answer,True
1920,0.6994791666666667,0.6043478260869565,0.7230169050715215,0.6583777383066903,556,787,364,213,Llama3.1-70B AP After,Human Answer,Human Answer,True
1920,0.7833333333333333,0.784219001610306,0.6332899869960988,0.7007194244604317,487,1017,134,282,Llama3.1-8B base,Human Answer,Human Answer,True
1920,0.7942708333333334,0.8847736625514403,0.5591677503250976,0.6852589641434262,430,1095,56,339,Llama3.1-8B FT,Human Answer,Human Answer,True
1920,0.6822916666666666,0.590443686006826,0.6749024707412223,0.6298543689320388,519,791,360,250,Llama3.1-8B AP Before,Human Answer,Human Answer,True
1920,0.5588541666666667,0.4671163575042159,0.7204161248374512,0.5667519181585677,554,519,632,215,Llama3.1-8B AP,Human Answer,Human Answer,True
1920,0.5390625,0.4475587703435805,0.6436931079323797,0.528,495,540,611,274,Llama3.1-8B AP After,Human Answer,Human Answer,True
840,0.9523809523809523,0.9036144578313253,0.9336099585062241,0.9183673469387756,225,575,24,16,GPT-5 base,Human Answer – Yes/No questions,Human Answer,True
840,0.9095238095238095,0.8837209302325582,0.7883817427385892,0.8333333333333334,190,574,25,51,GPT-4o base,Human Answer – Yes/No questions,Human Answer,True
840,0.9488095238095238,0.9159663865546218,0.9045643153526971,0.9102296450939457,218,579,20,23,GPT-4o FT,Human Answer – Yes/No questions,Human Answer,True
840,0.8773809523809524,0.73,0.9087136929460581,0.8096118299445472,219,518,81,22,GPT-4o AP Before,Human Answer – Yes/No questions,Human Answer,True
840,0.9,0.7773851590106007,0.9128630705394191,0.8396946564885495,220,536,63,21,GPT-4o AP,Human Answer – Yes/No questions,Human Answer,True
840,0.9083333333333333,0.828,0.8589211618257261,0.8431771894093686,207,556,43,34,GPT-4o AP After,Human Answer – Yes/No questions,Human Answer,True
840,0.8773809523809524,0.8136363636363636,0.7427385892116183,0.7765726681127982,179,558,41,62,Llama3.1-70B base,Human Answer – Yes/No questions,Human Answer,True
840,0.9202380952380952,0.9484536082474226,0.7634854771784232,0.8459770114942528,184,589,10,57,Llama3.1-70B FT,Human Answer – Yes/No questions,Human Answer,True
840,0.8678571428571429,0.7083333333333334,0.91701244813278,0.7992766726943943,221,508,91,20,Llama3.1-70B AP Before,Human Answer – Yes/No questions,Human Answer,True
840,0.8202380952380952,0.6222826086956522,0.950207468879668,0.7520525451559934,229,460,139,12,Llama3.1-70B AP,Human Answer – Yes/No questions,Human Answer,True
840,0.7511904761904762,0.5379146919431279,0.941908713692946,0.6847662141779788,227,404,195,14,Llama3.1-70B AP After,Human Answer – Yes/No questions,Human Answer,True
840,0.8666666666666667,0.7654320987654321,0.7717842323651453,0.768595041322314,186,542,57,55,Llama3.1-8B base,Human Answer – Yes/No questions,Human Answer,True
840,0.8892857142857142,0.8775510204081632,0.7136929460580913,0.7871853546910755,172,575,24,69,Llama3.1-8B FT,Human Answer – Yes/No questions,Human Answer,True
840,0.7726190476190476,0.5644329896907216,0.9087136929460581,0.6963434022257551,219,430,169,22,Llama3.1-8B AP Before,Human Answer – Yes/No questions,Human Answer,True
840,0.6238095238095238,0.4301675977653631,0.9585062240663901,0.5938303341902313,231,293,306,10,Llama3.1-8B AP,Human Answer – Yes/No questions,Human Answer,True
840,0.5928571428571429,0.4115586690017513,0.975103734439834,0.5788177339901478,235,263,336,6,Llama3.1-8B AP After,Human Answer – Yes/No questions,Human Answer,True
